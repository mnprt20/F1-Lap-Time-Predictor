# F1 Lap Time Analysis & Prediction

This project analyzes and predicts Formula 1 lap times using data from the 2023 Bahrain Grand Prix Qualifying session. It leverages the [FastF1](https://theoehrly.github.io/Fast-F1/) library to fetch session data, preprocesses it, explores features, and applies machine learning models to predict lap times.

## Features
- **Data Acquisition:** Fetches F1 session data using FastF1 and saves it as a CSV.
- **Data Preprocessing:** Cleans, encodes, and prepares the data for analysis and modeling.
- **Exploratory Data Analysis:** Visualizes distributions, relationships, and correlations between features and lap times.
- **Modeling:** Compares Linear Regression, Random Forest, and XGBoost models for lap time prediction.
- **Model Evaluation:** Compares models using Mean Squared Error (MSE) and R² score, and saves the best model.

## Workflow
1. **Fetch Data:**
   - Uses FastF1 to download qualifying session data for the 2023 Bahrain GP.
   - Extracts relevant lap information and saves it to `lap_times_bahrain_2023_q.csv`.
2. **Preprocess Data:**
   - Handles missing values, encodes categorical variables, and standardizes features.
   - Removes duplicates and resets indices.
3. **Exploratory Data Analysis:**
   - Visualizes numeric and categorical features using histograms, boxplots, scatter plots, and pairplots.
   - Analyzes feature correlations with lap time.
4. **Modeling:**
   - Splits data into training and test sets.
   - Trains and evaluates Linear Regression, Random Forest, and XGBoost models.
   - Compares model performance and visualizes results.
5. **Model Saving:**
   - Saves the best-performing model (Random Forest) and all trained models as `.pkl` files for future use.

## Results
- **Best Model:** Random Forest
- **Performance:**
  - MSE: ~108
  - R²: ~0.52
- Random Forest outperformed Linear Regression and XGBoost in both error minimization and explained variance.

## Dependencies
- Python 3.7+
- [FastF1](https://theoehrly.github.io/Fast-F1/)
- pandas
- numpy
- scikit-learn
- matplotlib
- seaborn
- xgboost
- joblib

Install dependencies with:
```bash
pip install fastf1 pandas numpy scikit-learn matplotlib seaborn xgboost joblib
```

## How to Run
1. **Clone or download this repository to your local machine.**
2. **Install the required dependencies** (see above).
3. **Open the `laptime.ipynb` notebook** using Jupyter Notebook, JupyterLab, or VSCode with the Jupyter extension.
4. **Run all cells in order:**
   - The notebook will automatically fetch the F1 data, preprocess it, perform analysis, train models, and display/save results.
   - Model files (e.g., `random_forest_best_model.pkl`) and the processed CSV will be generated in your working directory.
5. **Review the outputs:**
   - Visualizations and model performance metrics will be shown in the notebook output cells.

## Usage
1. Open and run `laptime.ipynb` in Jupyter Notebook or VSCode.
2. The notebook will fetch data, preprocess, analyze, train models, and save results.
3. Review the visualizations and model performance summaries in the notebook output.

## File Structure
- `laptime.ipynb` — Main notebook for data analysis and modeling
- `lap_times_bahrain_2023_q.csv` — Processed lap time data (generated by the notebook)
- `*_model.pkl` — Saved trained models (generated by the notebook)

## Acknowledgements
- [FastF1](https://theoehrly.github.io/Fast-F1/) for F1 data access
- Formula 1 for the data

---
Feel free to modify the notebook to analyze other sessions or experiment with additional features and models. 
